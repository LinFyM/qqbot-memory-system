# -*- coding: utf-8 -*-
"""
æ¶ˆæ¯é˜Ÿåˆ—æ¨¡å—
å¤„ç†æ¶ˆæ¯é˜Ÿåˆ—ã€ä»»åŠ¡è°ƒåº¦ã€æ‰“æ–­æœºåˆ¶ç­‰
"""
import queue
import logging
import threading
import time
import os
from datetime import datetime
from dataclasses import dataclass
from typing import Dict, Any, Optional

from chat.history_manager import (
    get_chat_history,
    set_chat_history,
    maintain_chat_history,
    chat_history_lock,
)
from chat.reply_handler import generate_reply, truncate_history_by_tokens
from chat.prompting import format_multimodal_message, parse_action_commands, build_system_prompt
from utils.cq import extract_cq_image_urls, extract_cq_video_urls, extract_cq_audio_urls, extract_cq_file_urls, extract_http_urls
import services.media as media_service
from services.asr import transcribe_audio
from services.fetch import fetch_url_content
from services.extractors import extract_text_and_images_from_file
from utils.metrics import metrics_add

_log = logging.getLogger(__name__)

# æ¶ˆæ¯é˜Ÿåˆ—
message_queue = queue.Queue()
queue_lock = threading.Lock()
worker_thread_started = False

# æ­£åœ¨å¤„ç†çš„èŠå¤©ï¼ˆç”¨äºä¸­æ–­åŒä¸€èŠå¤©å†…çš„æ—§æ¶ˆæ¯ï¼‰
# {chat_id: {"interrupt_event": Event, "response_dict": dict, "start_time": float, "lock": Lock}}
processing_chats: Dict[str, Dict[str, Any]] = {}


@dataclass
class MessageTask:
    """æ¶ˆæ¯å¤„ç†ä»»åŠ¡"""
    chat_type: str  # "group" æˆ– "private"
    chat_id: str  # ç¾¤IDæˆ–ç”¨æˆ·ID
    data: Dict[str, Any]  # åŸå§‹è¯·æ±‚æ•°æ®
    response_dict: Dict[str, Any]  # å“åº”å­—å…¸


def process_message_task(
    task: MessageTask,
    model,
    processor,
    memory_db,
    recall_token_ids,
    config,
    server_base_url,
    image_upload_dir,
    video_upload_dir,
    audio_upload_dir,
    file_upload_dir,
    is_training,
    training_lock,
    model_lock
):
    """
    å¤„ç†å•ä¸ªæ¶ˆæ¯ä»»åŠ¡
    
    Args:
        task: æ¶ˆæ¯ä»»åŠ¡
        model: æ¨¡å‹å®ä¾‹
        processor: å¤„ç†å™¨å®ä¾‹
        memory_db: è®°å¿†æ•°æ®åº“
        recall_token_ids: ç‰¹æ®Štoken IDs
        config: é…ç½®å­—å…¸
        server_base_url: æœåŠ¡å™¨åŸºç¡€URL
        image_upload_dir: å›¾ç‰‡ä¸Šä¼ ç›®å½•
        video_upload_dir: è§†é¢‘ä¸Šä¼ ç›®å½•
        audio_upload_dir: éŸ³é¢‘ä¸Šä¼ ç›®å½•
        file_upload_dir: æ–‡ä»¶ä¸Šä¼ ç›®å½•
        is_training: æ˜¯å¦å¤„äºè®­ç»ƒæ¨¡å¼
        training_lock: è®­ç»ƒé”
        model_lock: æ¨¡å‹é”
    """
    # æ£€æŸ¥è®­ç»ƒæ¨¡å¼
    with training_lock:
        if is_training:
            _log.warning("âš ï¸ å½“å‰å¤„äºè®­ç»ƒæ¨¡å¼ï¼Œæ‹’ç»å¤„ç†æ¶ˆæ¯")
            if task.response_dict:
                task.response_dict["reply"] = ""
                task.response_dict["should_reply"] = False
                task.response_dict["error"] = "æœåŠ¡å™¨æ­£åœ¨è®­ç»ƒä¸­"
                task.response_dict["status"] = "error"
                task.response_dict["status_code"] = 503
            return
    
    chat_id = task.chat_id
    chat_type = task.chat_type
    data = task.data
    response_dict = task.response_dict
    
    try:
        start_time = time.time()
        metrics_add("requests_total", 1)
        
        # æ£€æŸ¥æ‰“æ–­
        old_task_interrupted = False
        with queue_lock:
            if chat_id in processing_chats:
                # ä¸­æ–­æ—§æ¶ˆæ¯å¤„ç†
                old_processing = processing_chats[chat_id]
                old_interrupt = old_processing["interrupt_event"]
                old_interrupt.set()
                old_task_interrupted = True
                _log.info(f"âš ï¸ ä¸­æ–­èŠå¤© {chat_id} çš„æ—§æ¶ˆæ¯å¤„ç†ï¼ˆæ—§ä»»åŠ¡æ­£åœ¨å¤„ç†ä¸­ï¼‰")
            
            # åˆ›å»ºæ–°çš„ä¸­æ–­äº‹ä»¶ï¼ˆæ–°ä»»åŠ¡ä½¿ç”¨ï¼‰
            interrupt_event = threading.Event()
            processing_chats[chat_id] = {
                "interrupt_event": interrupt_event,
                "response_dict": response_dict,
                "start_time": start_time,
                "lock": threading.Lock()
            }
        
        # å¦‚æœä¸­æ–­äº†æ—§ä»»åŠ¡ï¼Œç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©æ—§ä»»åŠ¡æ£€æµ‹åˆ°ä¸­æ–­å¹¶é€€å‡º
        if old_task_interrupted:
            time.sleep(0.3)  # ç»™æ—§ä»»åŠ¡ä¸€äº›æ—¶é—´æ£€æµ‹ä¸­æ–­å¹¶é€€å‡º
            
            # å†æ¬¡æ£€æŸ¥æ˜¯å¦ä»ç„¶æ˜¯æœ€æ–°çš„ä»»åŠ¡ï¼ˆå¯èƒ½åœ¨è¿™æœŸé—´åˆæœ‰æ–°æ¶ˆæ¯åˆ°è¾¾ï¼‰
            with queue_lock:
                current_processing = processing_chats.get(chat_id)
                if current_processing and current_processing["response_dict"] is not response_dict:
                    # å·²ç»æœ‰æ›´æ–°çš„ä»»åŠ¡äº†ï¼Œå½“å‰ä»»åŠ¡åº”è¯¥é€€å‡º
                    _log.info(f"âš ï¸ èŠå¤© {chat_id} çš„ä»»åŠ¡åœ¨ç­‰å¾…æœŸé—´å·²è¢«æ›´æ–°çš„æ¶ˆæ¯æ›¿æ¢ï¼Œé€€å‡ºå¤„ç†")
                    return
                
                # å¦‚æœå½“å‰ä»»åŠ¡ä»ç„¶æ˜¯æœ€æ–°çš„ï¼Œç¡®ä¿interrupt_eventæ²¡æœ‰è¢«é”™è¯¯è®¾ç½®
                # å› ä¸ºæˆ‘ä»¬æ˜¯æ–°ä»»åŠ¡ï¼Œinterrupt_eventåº”è¯¥æ˜¯æœªè®¾ç½®çš„
                if interrupt_event.is_set():
                    _log.warning(f"âš ï¸ èŠå¤© {chat_id} çš„æ–°ä»»åŠ¡interrupt_eventè¢«é”™è¯¯è®¾ç½®ï¼Œé‡ç½®")
                    interrupt_event.clear()
        
        try:
            # æå–å†…å®¹
            content = data.get("content", "")
            timestamp = data.get("timestamp", time.time())
            time_str = datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")
            
            if chat_type == "group":
                group_id = str(data.get("group_id") or chat_id)
                group_name = data.get("group_name", f"ç¾¤{group_id}")
                user_id = str(data.get("user_id") or "")
                user_nickname = data.get("user_nickname", f"ç”¨æˆ·{user_id}") if user_id else data.get("user_nickname", "æœªçŸ¥ç”¨æˆ·")
                user_card = data.get("user_card", user_nickname)
                display_name = user_card if user_card else user_nickname
                _log.info(f"ğŸ” ç¾¤èŠæ¶ˆæ¯å†…å®¹åˆ†æ({group_id}/{display_name}): {content[:100]}...")
            else:
                group_name = None
                user_id = str(data.get("user_id") or chat_id)
                user_nickname = data.get("user_nickname", f"ç”¨æˆ·{user_id}")
                display_name = user_nickname
                _log.info(f"ğŸ” ç§èŠæ¶ˆæ¯å†…å®¹åˆ†æ({user_id}): {content[:100]}...")
            
            # æå–CQç 
            cleaned_content, image_urls = extract_cq_image_urls(content)
            img_sample = f"ï¼Œç¤ºä¾‹: {image_urls[:3]}" if image_urls else ""
            _log.info(f"ğŸ“· å›¾ç‰‡CQç æå–: æ‰¾åˆ° {len(image_urls)} ä¸ª{img_sample}")
            
            _, video_urls = extract_cq_video_urls(content)
            video_sample = f"ï¼Œç¤ºä¾‹: {video_urls[:3]}" if video_urls else ""
            _log.info(f"ğŸ¥ è§†é¢‘CQç æå–: æ‰¾åˆ° {len(video_urls)} ä¸ª{video_sample}")
            
            _, audio_urls = extract_cq_audio_urls(content)
            if audio_urls:
                _log.info(f"ğŸµ è¯­éŸ³CQç æå–: æ‰¾åˆ° {len(audio_urls)} ä¸ª")
            
            _, file_urls = extract_cq_file_urls(content)
            if file_urls:
                _log.info(f"ğŸ“„ æ–‡ä»¶CQç æå–: æ‰¾åˆ° {len(file_urls)} ä¸ª")
            
            # å¤„ç†åª’ä½“URL
            video_urls.extend(data.get("video_urls", []))
            
            # ä¸‹è½½åª’ä½“
            cached_image_urls = []
            if image_urls:
                _log.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½ {len(image_urls)} ä¸ªå›¾ç‰‡...")
                for url in image_urls:
                    cached = media_service.download_image_to_storage(
                        url, image_upload_dir, server_base_url,
                        metrics_add, _log
                    )
                    cached_image_urls.append(cached or url)
                image_urls = cached_image_urls
            
            cached_video_urls = []
            if video_urls:
                _log.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½ {len(video_urls)} ä¸ªè§†é¢‘...")
                for url in video_urls:
                    cached = media_service.download_video_to_storage(
                        url, video_upload_dir, server_base_url,
                        metrics_add, _log
                    )
                    cached_video_urls.append(cached or url)
                video_urls = cached_video_urls
            
            # å¤„ç†è¯­éŸ³æ¶ˆæ¯ï¼ˆASRï¼‰
            if audio_urls:
                _log.info(f"ğŸ“¥ å¼€å§‹å¤„ç† {len(audio_urls)} ä¸ªè¯­éŸ³æ¶ˆæ¯...")
                for url in audio_urls:
                    # ä¸‹è½½è¯­éŸ³
                    cached_audio = media_service.download_audio_to_storage(
                        url, audio_upload_dir, server_base_url,
                        metrics_add, _log
                    )
                    
                    if cached_audio:
                        # è½¬æ¢ä¸ºæœ¬åœ°è·¯å¾„
                        if cached_audio.startswith(server_base_url):
                            filename = cached_audio.split("/")[-1]
                            local_path = f"{audio_upload_dir}/{filename}"
                            
                            # æ‰§è¡ŒASR
                            try:
                                text = transcribe_audio(local_path, metrics_add, _log)
                                if text:
                                    _log.info(f"âœ… è¯­éŸ³è½¬å†™æˆåŠŸ: {text}")
                                    content += f"\n[è¯­éŸ³è½¬å†™]: {text}"
                            except Exception as e:
                                _log.warning(f"âš ï¸ ASRè½¬å†™å¤±è´¥: {e}")
            
            # å¤„ç†æ–‡ä»¶æ¶ˆæ¯ï¼ˆä¸‹è½½å¹¶æå–æ–‡æœ¬/å›¾ç‰‡ï¼‰
            if file_urls:
                _log.info(f"ğŸ“¥ å¼€å§‹å¤„ç† {len(file_urls)} ä¸ªæ–‡ä»¶...")
                file_texts = []
                for url in file_urls:
                    # ä¸‹è½½æ–‡ä»¶
                    cached_file = media_service.download_file_to_storage(
                        url, file_upload_dir, server_base_url,
                        metrics_add, _log
                    )
                    
                    if cached_file:
                        # è½¬æ¢ä¸ºæœ¬åœ°è·¯å¾„
                        if cached_file.startswith(server_base_url):
                            filename = cached_file.split("/")[-1]
                            local_path = f"{file_upload_dir}/{filename}"
                            
                            try:
                                # æå–æ–‡æœ¬å’Œå›¾ç‰‡
                                text, images = extract_text_and_images_from_file(
                                    local_path, image_upload_dir, metrics_add, _log
                                )
                                
                                if text:
                                    file_texts.append(text)
                                    _log.info(f"âœ… æ–‡ä»¶æ–‡æœ¬æå–æˆåŠŸ: {len(text)}å­—ç¬¦")
                                
                                # å°†æå–çš„å›¾ç‰‡æ·»åŠ åˆ°image_urls
                                for img_path in images:
                                    filename = os.path.basename(img_path)
                                    img_url = f"{server_base_url.rstrip('/')}/static/images/{filename}"
                                    if img_url not in image_urls:
                                        image_urls.append(img_url)
                                        _log.info(f"âœ… æ–‡ä»¶å›¾ç‰‡æå–æˆåŠŸ: {filename}")
                                        
                            except Exception as e:
                                _log.warning(f"âš ï¸ æ–‡ä»¶æå–å¤±è´¥: {e}")
                
                # å°†æ–‡ä»¶æ–‡æœ¬è¿½åŠ åˆ°å†…å®¹
                if file_texts:
                    file_content = "\n\n".join([f"ã€æ–‡ä»¶å†…å®¹{i+1}ã€‘\n{t}" for i, t in enumerate(file_texts)])
                    content = (content + "\n\n" if content else "") + file_content
            
            # å¤„ç†ç½‘é¡µé“¾æ¥ï¼ˆæŠ“å–å†…å®¹ï¼‰
            http_urls = extract_http_urls(content)
            if http_urls:
                _log.info(f"ğŸŒ æ£€æµ‹åˆ° {len(http_urls)} ä¸ªç½‘é¡µé“¾æ¥ï¼Œå°è¯•æŠ“å–å†…å®¹...")
                web_contents = []
                for url in http_urls:
                    try:
                        web_text = fetch_url_content(url, metrics_add, _log)
                        if web_text:
                            web_contents.append(f"ã€ç½‘é¡µå†…å®¹: {url}ã€‘\n{web_text}")
                            _log.info(f"âœ… ç½‘é¡µæŠ“å–æˆåŠŸ: {url} ({len(web_text)}å­—ç¬¦)")
                    except Exception as e:
                        _log.warning(f"âš ï¸ ç½‘é¡µæŠ“å–å¤±è´¥ {url}: {e}")
                
                if web_contents:
                    web_content_str = "\n\n".join(web_contents)
                    content = (content + "\n\n" if content else "") + web_content_str
            
            media_info = ""
            if image_urls:
                media_info += f" [åŒ…å«{len(image_urls)}å¼ å›¾ç‰‡]"
            if video_urls:
                media_info += f" [åŒ…å«{len(video_urls)}ä¸ªè§†é¢‘]"
            if audio_urls:
                media_info += f" [åŒ…å«{len(audio_urls)}æ®µè¯­éŸ³]"
            if file_urls:
                media_info += f" [åŒ…å«{len(file_urls)}ä¸ªæ–‡ä»¶]"
            
            prefix = f"[{time_str}] {display_name}(QQ:{user_id})ï¼š"
            formatted_message = f"{prefix}{cleaned_content}" if cleaned_content else prefix
            
            _log.info(f"ğŸ—¨ï¸ æ”¶åˆ°{ 'ç¾¤èŠ' if chat_type == 'group' else 'ç§èŠ' }æ¶ˆæ¯ {chat_id}{media_info}: {formatted_message[:80]}...")
            
            if image_urls or video_urls:
                user_message = format_multimodal_message(formatted_message, image_urls, video_urls)
            else:
                user_message = [{"type": "text", "text": formatted_message}]
            
            max_history = config.get("chat_history", {}).get("max_history_length", 200)
            with chat_history_lock:
                history = list(get_chat_history(chat_type, chat_id))
                history.append({"role": "user", "content": user_message, "timestamp": timestamp})
                history, removed_messages = maintain_chat_history(chat_type, chat_id, history, max_history)
                set_chat_history(chat_type, chat_id, history)
                chat_history_snapshot = history.copy()
            if removed_messages:
                _log.info(f"ğŸ’¾ å†å²è¶…é•¿ï¼Œè¿½åŠ ä¿å­˜ {len(removed_messages)} æ¡æ—§æ¶ˆæ¯åˆ°å­˜å‚¨ï¼ˆ{chat_type} {chat_id}ï¼‰")
                threading.Thread(
                    target=save_chat_history_to_storage,
                    args=(config, chat_type, chat_id, removed_messages),
                    daemon=True
                ).start()
            _log.info(f"ğŸ“ ç»´æŠ¤åå†å²é•¿åº¦: {len(chat_history_snapshot)}ï¼ˆ{chat_type} {chat_id}ï¼‰")
            
            # åœ¨ç”Ÿæˆå‰å†æ¬¡æ£€æŸ¥æ˜¯å¦ä»ç„¶æ˜¯æœ€æ–°ä»»åŠ¡
            with queue_lock:
                current_processing = processing_chats.get(chat_id)
                if current_processing and current_processing["response_dict"] is not response_dict:
                    _log.info(f"âš ï¸ èŠå¤© {chat_id} çš„ä»»åŠ¡åœ¨ç”Ÿæˆå‰å·²è¢«æ–°æ¶ˆæ¯æ›¿æ¢ï¼Œé€€å‡ºå¤„ç†")
                    return
                if interrupt_event.is_set():
                    _log.warning(f"âš ï¸ èŠå¤© {chat_id} çš„ä»»åŠ¡åœ¨ç”Ÿæˆå‰æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ¸…é™¤åç»§ç»­")
                    interrupt_event.clear()
            
            # æˆªæ–­å†å²ï¼ˆåŸºäºtokenæ•°ï¼Œæˆªæ–­åä¼šæ›´æ–°å†…å­˜ä¸­çš„å†å²ï¼‰
            chat_context = {}
            if chat_type == "group":
                chat_context = {"group_id": chat_id, "group_name": group_name or chat_id}
                if user_id:
                    chat_context["user_id"] = user_id
                if user_nickname:
                    chat_context["user_nickname"] = user_nickname
                if display_name:
                    chat_context["display_name"] = display_name
            elif chat_type == "private":
                chat_context = {"user_id": user_id or chat_id, "user_nickname": user_nickname or chat_id}
            
            system_prompt = build_system_prompt(config, chat_type, chat_context)
            max_tokens = config.get("chat_history", {}).get("max_input_tokens", 32000)
            
            _log.info(f"ğŸ“Š å¼€å§‹æˆªæ–­å†å²ï¼ˆ{chat_type} {chat_id}ï¼‰ï¼Œmax_tokens={max_tokens}")
            original_history_len = len(chat_history_snapshot)
            generation_history = truncate_history_by_tokens(
                processor,
                chat_history_snapshot.copy(),
                system_prompt,
                chat_type,
                chat_id,
                config,
                max_tokens,
                interrupt_event
            )
            if len(generation_history) < original_history_len:
                _log.info(f"âœ‚ï¸ å†å²æˆªæ–­: {original_history_len} -> {len(generation_history)}ï¼ˆ{chat_type} {chat_id}ï¼‰")
                # æ›´æ–°å†…å­˜ä¸­çš„å†å²ï¼Œç§»é™¤è¢«æˆªæ–­çš„æ¶ˆæ¯
                with chat_history_lock:
                    set_chat_history(chat_type, chat_id, generation_history)
                    _log.info(f"ğŸ’¾ å·²æ›´æ–°å†…å­˜ä¸­çš„å†å²ï¼Œç§»é™¤ {original_history_len - len(generation_history)} æ¡æ¶ˆæ¯ï¼ˆ{chat_type} {chat_id}ï¼‰")
            else:
                _log.info(f"ğŸ“ å†å²é•¿åº¦ {len(generation_history)}ï¼Œæœªè¶…è¿‡ä¸Šé™ï¼ˆ{chat_type} {chat_id}ï¼‰")
            
            # è·å–ç”Ÿæˆå‚æ•°
            gen_config = config.get("generation", {})
            max_new_tokens = gen_config.get("max_new_tokens", 1000)
            temperature = gen_config.get("temperature", 1.0)
            
            # ç”Ÿæˆå›å¤
            _log.info(f"ğŸ§  å¼€å§‹ç”Ÿæˆå›å¤ï¼ˆ{chat_type} {chat_id}ï¼‰...")
            reply, should_reply, interrupted = generate_reply(
                model,
                processor,
                memory_db,
                recall_token_ids,
                config,
                generation_history,
                max_new_tokens=max_new_tokens,
                temperature=temperature,
                chat_type=chat_type,
                chat_context=chat_context,
                interrupt_event=interrupt_event,
                chat_id=chat_id,
                response_dict=response_dict,
                log_full_io=True,
                is_training=is_training,
                training_lock=training_lock,
                model_lock=model_lock
            )
            
            if interrupted:
                _log.warning(f"âš ï¸ ç”Ÿæˆè¢«ä¸­æ–­ï¼ˆ{chat_type} {chat_id}ï¼‰")
                metrics_add("interruptions", 1)
                with queue_lock:
                    current_processing = processing_chats.get(chat_id)
                    if current_processing and current_processing["response_dict"] is response_dict:
                        response_dict.update({
                            "status": "success",
                            "should_reply": False,
                            "reply": "",
                            "status_code": 200
                        })
                        _log.info(f"âœ… å·²æ›´æ–°ä¸­æ–­å“åº”ï¼ˆ{chat_type} {chat_id}ï¼‰")
                return
            
            _log.info(f"ğŸ“¤ ç”Ÿæˆç»“æœ: should_reply={should_reply}, reply_length={len(reply) if reply else 0}")
            
            # ç”Ÿæˆç»“æŸåï¼Œç¡®è®¤æ˜¯å¦ä»æ˜¯æœ€æ–°ä»»åŠ¡
            with queue_lock:
                current_processing = processing_chats.get(chat_id)
                if current_processing and current_processing["response_dict"] is not response_dict:
                    _log.info(f"âš ï¸ èŠå¤© {chat_id} çš„ä»»åŠ¡åœ¨ç”Ÿæˆå®Œæˆåè¢«æ–°æ¶ˆæ¯æ›¿æ¢ï¼Œè·³è¿‡åç»­æ­¥éª¤")
                    return
                if interrupt_event.is_set():
                    _log.info(f"âš ï¸ èŠå¤© {chat_id} çš„ä»»åŠ¡åœ¨ç”Ÿæˆå®Œæˆåæ£€æµ‹åˆ°ä¸­æ–­ï¼Œè·³è¿‡æ›´æ–°å†å²")
                    return
            
            # ä¿å­˜å›å¤åˆ°å†å²
            with chat_history_lock:
                latest_history = list(get_chat_history(chat_type, chat_id))
                if should_reply and reply:
                    metrics_add("replies_sent", 1)
                    assistant_text = reply
                else:
                    metrics_add("no_reply", 1)
                    assistant_text = "<no_reply>"
                latest_history.append({
                    "role": "assistant",
                    "content": [{"type": "text", "text": assistant_text}],
                    "timestamp": time.time()
                })
                latest_history, removed_messages = maintain_chat_history(chat_type, chat_id, latest_history, max_history)
                set_chat_history(chat_type, chat_id, latest_history)
            if removed_messages:
                _log.info(f"ğŸ’¾ assistantå†å²æˆªæ–­ï¼Œä¿å­˜ {len(removed_messages)} æ¡æ—§æ¶ˆæ¯åˆ°å­˜å‚¨ï¼ˆ{chat_type} {chat_id}ï¼‰")
                threading.Thread(
                    target=save_chat_history_to_storage,
                    args=(config, chat_type, chat_id, removed_messages),
                    daemon=True
                ).start()
            _log.info(f"ğŸ’¾ å·²æ›´æ–°assistantæ¶ˆæ¯åˆ°å†å²ï¼ˆ{chat_type} {chat_id}ï¼‰")
            
            # æå–åŠ¨ä½œæŒ‡ä»¤
            actions = parse_action_commands(reply) if reply else []
            if actions:
                _log.info(f"ğŸ¬ æå–åˆ° {len(actions)} ä¸ªåŠ¨ä½œæŒ‡ä»¤: {[a.get('type') for a in actions]}")
            
            # æ›´æ–°å“åº”å‰å†æ¬¡ç¡®è®¤
            with queue_lock:
                current_processing = processing_chats.get(chat_id)
                if current_processing and current_processing["response_dict"] is response_dict:
                    if interrupt_event.is_set():
                        _log.warning(f"âš ï¸ èŠå¤© {chat_id} çš„ä»»åŠ¡åœ¨æ›´æ–°å“åº”å‰è¢«ä¸­æ–­ï¼Œè·³è¿‡å“åº”æ›´æ–°")
                        return
                    response_dict["reply"] = reply if should_reply else ""
                    response_dict["should_reply"] = should_reply
                    response_dict["actions"] = actions
                    response_dict["status"] = "success"
                    response_dict["status_code"] = 200
                    _log.info(f"âœ… å·²æ›´æ–°å“åº”ï¼ˆ{chat_type} {chat_id}ï¼‰ï¼Œshould_reply={should_reply}")
                else:
                    _log.warning(f"âš ï¸ èŠå¤© {chat_id} çš„ä»»åŠ¡åœ¨æ›´æ–°å“åº”å‰å·²è¢«æ›¿æ¢ï¼Œè·³è¿‡")
            
            elapsed = time.time() - start_time
            metrics_add("response_time", elapsed)
            _log.info(f"âœ… æ¶ˆæ¯å¤„ç†å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}s ï¼ˆ{chat_type} {chat_id}ï¼‰")
            
        finally:
            with queue_lock:
                current_processing = processing_chats.get(chat_id)
                if current_processing and current_processing["response_dict"] is response_dict:
                    del processing_chats[chat_id]
    
    except Exception as e:
        _log.error(f"âŒ å¤„ç†æ¶ˆæ¯ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        response_dict["status"] = "error"
        response_dict["error"] = str(e)
        response_dict["status_code"] = 500


def message_queue_worker(model, processor, memory_db, recall_token_ids, config, 
                        server_base_url, image_upload_dir, video_upload_dir, audio_upload_dir, file_upload_dir,
                        is_training_getter, training_lock, model_lock):
    """
    æ¶ˆæ¯é˜Ÿåˆ—å·¥ä½œçº¿ç¨‹
    
    Args:
        model: æ¨¡å‹å®ä¾‹
        processor: å¤„ç†å™¨å®ä¾‹
        memory_db: è®°å¿†æ•°æ®åº“
        recall_token_ids: ç‰¹æ®Štoken IDs
        config: é…ç½®å­—å…¸
        server_base_url: æœåŠ¡å™¨åŸºç¡€URL
        image_upload_dir: å›¾ç‰‡ä¸Šä¼ ç›®å½•
        video_upload_dir: è§†é¢‘ä¸Šä¼ ç›®å½•
        audio_upload_dir: éŸ³é¢‘ä¸Šä¼ ç›®å½•
        file_upload_dir: æ–‡ä»¶ä¸Šä¼ ç›®å½•
        is_training_getter: è·å–è®­ç»ƒçŠ¶æ€çš„å‡½æ•°
        training_lock: è®­ç»ƒé”
        model_lock: æ¨¡å‹é”
    """
    _log.info("ğŸ“‹ æ¶ˆæ¯é˜Ÿåˆ—å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨")
    
    while True:
        try:
            task = message_queue.get(timeout=1)
            _log.info(f"ğŸ”„ å¼€å§‹å¤„ç†æ¶ˆæ¯ä»»åŠ¡: {task.chat_type} {task.chat_id}")
            
            def _run_task(task_obj):
                """åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­æ‰§è¡Œä»»åŠ¡ï¼Œä¿æŒä¸v1.2ä¸€è‡´çš„å¹¶å‘æ‰“æ–­è¡Œä¸º"""
                try:
                    current_training = is_training_getter() if callable(is_training_getter) else is_training_getter
                    process_message_task(
                        task_obj,
                        model,
                        processor,
                        memory_db,
                        recall_token_ids,
                        config,
                        server_base_url,
                        image_upload_dir,
                        video_upload_dir,
                        audio_upload_dir,
                        file_upload_dir,
                        current_training,
                        training_lock,
                        model_lock
                    )
                except Exception as task_err:
                    _log.error(f"âŒ å¤„ç†æ¶ˆæ¯ä»»åŠ¡å¤±è´¥ï¼ˆ{task_obj.chat_type} {task_obj.chat_id}ï¼‰: {task_err}", exc_info=True)
            
            worker_thread = threading.Thread(target=_run_task, args=(task,), daemon=True)
            worker_thread.start()
            message_queue.task_done()
        except queue.Empty:
            continue
        except Exception as e:
            _log.error(f"âŒ é˜Ÿåˆ—å·¥ä½œçº¿ç¨‹é”™è¯¯: {e}", exc_info=True)

